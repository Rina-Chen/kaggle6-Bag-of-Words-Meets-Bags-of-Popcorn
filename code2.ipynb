{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7cd786de",
   "metadata": {},
   "source": [
    "在code的基础上通过未标记数据和 Word2Vec 增强泛化能力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e768a0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading punkt: <urlopen error [Errno 11004]\n",
      "[nltk_data]     getaddrinfo failed>\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from gensim.models import Word2Vec\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "nltk.download('punkt')\n",
    "\n",
    "unlabeled_data = pd.read_csv('unlabeledTrainData.tsv', delimiter='\\t', quoting=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82a09fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 文本清洗函数：去除HTML标签和非字母字符\n",
    "def clean_review(text):\n",
    "    text = re.sub(r'<.*?>', '', text) \n",
    "    text = re.sub(r'[^a-zA-Z]', ' ', text) \n",
    "    return text.lower()\n",
    "\n",
    "def preprocess_reviews(reviews):\n",
    "    tokenized_reviews = []\n",
    "    for review in reviews:\n",
    "        cleaned_review = clean_review(review)\n",
    "        words = nltk.word_tokenize(cleaned_review)\n",
    "        tokenized_reviews.append(words)\n",
    "    return tokenized_reviews\n",
    "\n",
    "tokenized_reviews = preprocess_reviews(unlabeled_data['review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "876fe06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_model = Word2Vec(\n",
    "    sentences=tokenized_reviews,  # 输入的分词文本\n",
    "    vector_size=100,              # 词向量维度\n",
    "    window=5,                     # 上下文窗口大小\n",
    "    min_count=5,                  # 最小词频\n",
    "    sg=1,                         # Skip-Gram模型 (sg=1)，CBOW为0\n",
    "    workers=4                     # 使用4个线程进行训练\n",
    ")\n",
    "\n",
    "word2vec_model.save(\"word2vec_model.model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "680a85e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_average_word_vectors(reviews, model, vector_size):\n",
    "    review_vectors = []\n",
    "    for review in reviews:\n",
    "        word_vectors = [model.wv[word] for word in review if word in model.wv]\n",
    "        if len(word_vectors) > 0:\n",
    "            avg_vector = np.mean(word_vectors, axis=0)\n",
    "        else:\n",
    "            avg_vector = np.zeros(vector_size)\n",
    "        review_vectors.append(avg_vector)\n",
    "    return np.array(review_vectors)\n",
    "\n",
    "train_review_vectors = get_average_word_vectors(tokenized_reviews, word2vec_model, vector_size=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ef395f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "验证集准确率: 0.8656\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "labeled_data = pd.read_csv('labeledTrainData.tsv', delimiter='\\t', quoting=3)\n",
    "labeled_reviews = preprocess_reviews(labeled_data['review'])\n",
    "\n",
    "labeled_review_vectors = get_average_word_vectors(labeled_reviews, word2vec_model, vector_size=100)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(labeled_review_vectors, labeled_data['sentiment'], test_size=0.2, random_state=42)\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_val)\n",
    "\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "print(f'验证集准确率: {accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c894c7cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "验证集准确率: 0.8422\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# 拆分训练集和验证集\n",
    "X_train, X_val, y_train, y_val = train_test_split(labeled_review_vectors, labeled_data['sentiment'], test_size=0.2, random_state=42)\n",
    "\n",
    "# 使用随机森林模型训练\n",
    "model_rf = RandomForestClassifier()\n",
    "model_rf.fit(X_train, y_train)\n",
    "\n",
    "# 验证集预测\n",
    "y_pred_rf = model_rf.predict(X_val)\n",
    "\n",
    "# 计算准确率\n",
    "accuracy_rf = accuracy_score(y_val, y_pred_rf)\n",
    "print(f'验证集准确率: {accuracy_rf:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aedfb9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36bf81e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
